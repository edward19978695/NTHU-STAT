# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZQtlwwjqN-CAyVE6OkKLFgBLsXcOiwQ-
"""

# Training progress bar
!pip install -q qqdm
import math
import cv2
import random
import numpy as np
import torch
from torch import nn
from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset, BatchSampler
import torchvision.transforms as transforms
import torch.nn.functional as F
from torch.autograd import Variable
import torchvision.models as models
from torch.optim import Adam, AdamW
from qqdm import qqdm, format_str
import pandas as pd
import matplotlib.pyplot as plt

# Load in original image
original_image = np.load("eye/data.npy")

# AE model
class conv_autoencoder(nn.Module):
    def __init__(self):
        super(conv_autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 12, 3, stride=1, padding=1),         
            nn.ReLU(),
            nn.Conv2d(12, 24, 3, stride=1, padding=1),        
            nn.ReLU(),
			      nn.Conv2d(24, 48, 3, stride=1, padding=1),         
            nn.ReLU(),
        )
        self.decoder = nn.Sequential(
			      nn.ConvTranspose2d(48, 24, 3, stride=1, padding=1),
            nn.ReLU(),
			      nn.ConvTranspose2d(24, 12, 3, stride=1, padding=1), 
            nn.ReLU(),
            nn.ConvTranspose2d(12, 3, 3, stride=1, padding=1),
            nn.Tanh(),
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# VAE model
class VAE(nn.Module):
    def __init__(self):
        super(VAE, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 12, 5, stride=1, padding=2),          
            nn.ReLU(), 
            nn.Conv2d(12, 24, 5, stride=1, padding=2),           
            nn.ReLU(), 
            nn.Conv2d(24, 48, 5, stride=1, padding=2),           
            nn.ReLU()
        )
        self.enc_out_1 = nn.Sequential(
            nn.Conv2d(48, 96, 5, stride=1, padding=2),  
            nn.ReLU(),
        )
        self.enc_out_2 = nn.Sequential(
            nn.Conv2d(48, 96, 5, stride=1, padding=2),
            nn.ReLU(),
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(96, 48, 5, stride=1, padding=2), 
            nn.ReLU(),
            nn.ConvTranspose2d(48, 24, 5, stride=1, padding=2), 
            nn.ReLU(),
			      nn.ConvTranspose2d(24, 12, 5, stride=1, padding=2), 
            nn.ReLU(),
            nn.ConvTranspose2d(12, 3, 5, stride=1, padding=2), 
            nn.Tanh(),
        )

    def encode(self, x):
        h1 = self.encoder(x)
        return self.enc_out_1(h1), self.enc_out_2(h1)

    def reparametrize(self, mu, logvar):
        std = logvar.mul(0.5).exp_()
        if torch.cuda.is_available():
            eps = torch.cuda.FloatTensor(std.size()).normal_()
        else:
            eps = torch.FloatTensor(std.size()).normal_()
        eps = Variable(eps)
        return eps.mul(std).add_(mu)

    def decode(self, z):
        return self.decoder(z)

    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparametrize(mu, logvar)
        return self.decode(z), mu, logvar

# Loss of VAE model : MSE + KLD
def loss_vae(recon_x, x, mu, logvar, criterion):
    """
    recon_x: generating images
    x: origin images
    mu: latent mean
    logvar: latent log variance
    """
    mse = criterion(recon_x, x)
    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)
    KLD = torch.mean(KLD_element).mul_(-0.5)
    return mse + KLD

class CustomTensorDataset(TensorDataset):
    """TensorDataset with support of transforms.
    """
    def __init__(self, tensors):
        self.tensors = tensors
        if tensors.shape[-1] == 3:
            self.tensors = tensors.permute(0, 3, 1, 2)
        
        self.transform = transforms.Compose([
          transforms.Lambda(lambda x: x.to(torch.float32)),
          transforms.Lambda(lambda x: 2. * x - 1.),
        ])
        
    def __getitem__(self, index):
        x = self.tensors[index]
        
        if self.transform:
            # mapping images to [-1.0, 1.0]
            x = self.transform(x)

        return x

    def __len__(self):
        return len(self.tensors)

# Training hyperparameters
num_epochs = 500
batch_size = 164
learning_rate = 1e-3

# Build training dataloader
x = torch.from_numpy(original_image)
train_dataset = CustomTensorDataset(x)

#train_sampler = SequentialSampler(train_dataset)
train_dataloader = DataLoader(train_dataset, shuffle=False, batch_size=batch_size)

# Model
model_type = 'cnn'   # selecting a model type from {'cnn', 'vae'}
model_classes = {'cnn': conv_autoencoder(), 'vae': VAE()}
model = model_classes[model_type].cuda()

# Loss and optimizer
criterion = nn.MSELoss()
# criterion = nn.L1Loss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

# Training
best_loss = np.inf
model.train()
qqdm_train = qqdm(range(num_epochs), desc=format_str('bold', 'Description'))
all_loss = list()
for epoch in qqdm_train:
    tot_loss = list()
    for data in train_dataloader:

        # ===================loading=====================
        img = data.float().cuda()
        output = model(img)
        if model_type in ['vae']:
            loss = loss_vae(output[0], img, output[1], output[2], criterion)
        else:
            loss = criterion(output, img)

        tot_loss.append(loss.item())
        # ===================backward====================
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    # ===================save_best====================
    mean_loss = np.mean(tot_loss)
    all_loss.append(mean_loss.item())
    if mean_loss < best_loss:
        best_loss = mean_loss
        torch.save(model, 'best_model_{}.pth'.format(model_type)) # save best model as .pth file
    # ===================log========================
    qqdm_train.set_infos({
        'epoch': f'{epoch + 1:.0f}/{num_epochs:.0f}',
        'loss': f'{mean_loss:.4f}',
    })

# Visualization
plt.subplot(2,1,1)
plt.plot(range(num_epochs)[:], all_loss[:], color = 'blue')
plt.xlabel('#Epoch')
plt.ylabel('Loss')
plt.title('Training of AE model')

plt.subplot(2,1,2)
plt.plot(range(num_epochs)[300:], all_loss[300:], color = 'blue')
plt.xlabel('#Epoch')
plt.ylabel('Loss')
plt.savefig('loss_AE.png', dpi = 300)
plt.show()